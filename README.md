# ğŸ” AI-Powered Fraud Risk Engine with LLM Explanations

This project is a backend microservice that evaluates the risk level of a payment transaction based on custom fraud heuristics. It uses an LLM (e.g., Gemini gemini-2.0-flash) to generate human-readable explanations for the risk score and supports Redis-based caching with graceful fallback logic.

---

## ğŸš€ Features

- âœ… Risk scoring based on:
  - High-risk email domains (e.g. `.ru`, `fraud.net`)
  - Large transaction amount
  - Repeated IP address or device fingerprint
- âœ… LLM-generated explanations (gemini-2.0-flash)
- âœ… Redis-based prompt caching with TTL
- âœ… Fallback to direct LLM call if Redis is down
- âœ… Fraud statistics endpoint (`/fraud-stats`)
- ğŸ§ª Easily testa




## ğŸ“¦ Tech Stack

- **Backend:** Node.js, Express, TypeScript
- **LLM API:** Gemini (gemini-2.0-flash compatible)
- **Caching:** Redis (via `redis` NPM package)
- **Runtime:** Local, Docker, or cloud-compatible

---

## ğŸ› ï¸ Setup Instructions

### 1ï¸âƒ£ Clone Repository

git clone https://github.com/<your-username>/fraud-risk-engine.git
cd fraud-risk-engine

### 2ï¸âƒ£ Install Dependencies

npm install

### 3ï¸âƒ£ Add Environment Variables

OPENAI_API_KEY=your_openai_api_key_here
REDIS_URL=redis://localhost:6379

### 4ï¸âƒ£ Start Redis (Optional if using local Redis)

docker run -d --name redis -p 6379:6379 redis

### 5ï¸âƒ£ Start the Server

npm run dev

### 5ï¸âƒ£ Swagger Documentation

[![Swagger Docs](https://img.shields.io/badge/API-Swagger-blue)](http://localhost:3000/api-docs)
